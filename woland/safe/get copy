package safe

import (
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path"
	"path/filepath"
	"time"

	"github.com/stregato/master/woland/core"
	"github.com/stregato/master/woland/sql"
	"github.com/stregato/master/woland/storage"
)

var ErrFileNotExist = fmt.Errorf("file does not exist") // Returned when a file does not exist
var MaxCacheSize = int64(128 * 1024 * 1024)             // Maximum size of the cache
var DelayForDestination = 100 * time.Millisecond        // Delay before checking if the file is downloaded to the specified destination
var currentCacheSize int64 = -1                         // Current size of the cache

type GetOptions struct {
	Destination string              `json:"destination"` // Track the file is downloaded to the specified destination. File must be closed within a second
	Async       func(Header, error) `json:"-"`           // When not nil, the download is asynchronous and the function is called when the download is complete or fails
	Progress    chan int64          `json:"progress"`    // Send progress updates to the channel
	FileId      uint64              `json:"fileId"`      // Get the file with the specified body ID
	NoCache     bool                `json:"noCache"`     // Do not cache the file
	CacheExpire time.Duration       `json:"cacheExpire"` // Cache expiration time
	Range       *storage.Range      `json:"range"`       // Range of bytes to read
	Sync        bool                `json:"sync"`        // Sync the headers before reading the file
}

func Get(s *Safe, bucket, name string, w io.Writer, options GetOptions) (Header, error) {
	core.Info("Getting %s/%s", bucket, name)

	if options.Sync {
		_, err := SyncBucket(s, bucket, SyncOptions{}, nil)
		if core.IsErr(err, nil, "cannot sync headers: %v", err) {
			return Header{}, err
		}
	}

	var data []byte
	err := sql.QueryRow("GET_LAST_HEADER", sql.Args{
		"safe":   s.Name,
		"bucket": bucket,
		"name":   name,
		"fileId": options.FileId,
	}, &data)
	if err == sql.ErrNoRows {
		core.Info("file %s/%s does not exist", bucket, name)
		return Header{}, ErrFileNotExist
	}
	if core.IsErr(err, nil, "cannot query file: %v", err) {
		return Header{}, err
	}

	var header Header
	err = json.Unmarshal(data, &header)
	if core.IsErr(err, nil, "cannot unmarshal header: %v", err) {
		return Header{}, err
	}
	core.Info("header for %s/%s found, fileId %d", bucket, name, header.FileId)

	w, err = decryptWriter(w, header.BodyKey, header.IV)
	if core.IsErr(err, nil, "cannot create decrypting writer: %v", err) {
		return Header{}, err
	}

	if options.Progress != nil {
		w = progressWriter(w, options.Progress)
		core.Info("Progress writer created")
	}
	if header.Attributes.Zip {
		core.Info("File is zipped, creating gunzip stream")
		w, err = gunzipStream(w)
		if core.IsErr(err, nil, "cannot decompress data: %v", err) {
			return Header{}, err
		}
		core.Info("Gzip stream created")
	}

	if !options.NoCache && header.Cached != "" {
		core.Info("Using cached file %s", header.Cached)
		s, err := os.Stat(header.Cached)
		if err == nil {
			if s.Size() == header.Size {
				r, err := os.Open(header.Cached)
				if err == nil {
					defer r.Close()
					if w != nil {
						_, err = io.Copy(w, r)
						core.IsErr(err, nil, "cannot copy cached file: %v", err)
					}
					if err == nil {
						return header, nil
					}
				}
			}
		}
		core.Info("Cannot open cached file: %v", err)
	}

	var cacheFile *os.File
	if !options.NoCache {
		core.Info("Creating cache file")
		cacheFile, err = getCacheFile(header)
		if core.IsErr(err, nil, "cannot create cache file: %v", err) {
			return Header{}, err
		}
	}

	if options.Async != nil {
		go func() {
			header, err := writeFile(s.stores[0], s.Name, bucket, options, header, w, cacheFile)
			options.Async(header, err)
		}()
		return header, nil
	} else {
		return writeFile(s.stores[0], s.Name, bucket, options, header, w, cacheFile)
	}
}

func getCacheFile(header Header) (*os.File, error) {
	if currentCacheSize < 0 {
		currentCacheSize = getCurrentCacheSize()
	}

	cacheFilename := filepath.Join(CacheFolder, fmt.Sprintf("%d.cache", header.FileId))
	cacheFile, err := os.Create(cacheFilename)
	if core.IsErr(err, nil, "cannot create cache file: %v", err) {
		return nil, err
	}
	return cacheFile, nil
}

func writeFile(store storage.Store, safeName, bucket string, options GetOptions, header Header, w io.Writer, cacheFile *os.File) (Header, error) {
	var err error

	if w != nil {
		w = io.MultiWriter(w, cacheFile)
	} else if cacheFile != nil {
		w = cacheFile
	} else {
		return Header{}, nil
	}

	dir := hashPath(bucket)
	fullname := path.Join(safeName, DataFolder, dir, BodyFolder, fmt.Sprintf("%d", header.FileId))

	err = store.Read(fullname, options.Range, w, nil)
	if core.IsErr(err, nil, "cannot read file: %v", err) {
		return Header{}, err
	}
	core.Info("Read %s[%d] into %s", header.Name, header.FileId, fullname)

	if options.Destination != "" || cacheFile != nil {
		updateHeaderInDB(safeName, bucket, header.FileId, func(h Header) Header {
			if options.Destination != "" {
				if h.Downloads == nil {
					h.Downloads = make(map[string]time.Time)
				}
				h.Downloads[options.Destination] = core.Now()
				core.Info("Added download location for %s: %s", header.Name, options.Destination)
			}
			if cacheFile != nil {
				h.Cached = cacheFile.Name()
				if options.CacheExpire > 0 {
					h.CachedExpires = core.Now().Add(options.CacheExpire)
				} else {
					h.CachedExpires = core.Now().Add(30 * 24 * time.Hour)
				}
				core.Info("Added cache location for %s: %s", header.Name, h.Cached)
				currentCacheSize += header.Size
				if currentCacheSize > MaxCacheSize {
					go removeOldestCacheFiles()
				}
			}
			return h
		})
	}

	core.Info("Wrote %s[%d]", header.Name, header.FileId)
	return header, nil
}

func getCurrentCacheSize() int64 {
	var cacheSize int64
	var cacheMap = make(map[string]time.Time)
	folderPath := CacheFolder

	_ = filepath.Walk(folderPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if !info.IsDir() {
			cacheSize += info.Size()
			cacheMap[path] = info.ModTime()
		}

		return nil
	})

	return cacheSize
}

func removeOldestCacheFiles() {
	for currentCacheSize > MaxCacheSize*9/10 {
		var header Header
		var saveName string
		var bucket string
		var data []byte
		err := sql.QueryRow("GET_CACHE_EXPIRE", nil, &saveName, &bucket, &data)
		if core.IsErr(err, nil, "cannot query file: %v", err) {
			return
		}
		err = json.Unmarshal(data, &header)
		if core.IsErr(err, nil, "cannot unmarshal header: %v", err) {
			return
		}

		os.Remove(header.Cached)
		currentCacheSize -= header.Size
		err = updateHeaderInDB(saveName, bucket, header.FileId, func(h Header) Header {
			h.Cached = ""
			h.CachedExpires = time.Time{}
			return h
		})
		core.IsErr(err, nil, "cannot save header to DB: %v", err)
	}
}
